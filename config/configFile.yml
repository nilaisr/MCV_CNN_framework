# Problem type
problem_type: 'classification' # Option: ['segmentation','classification']
# Model
model_type: 'VGG16'   # Options: ['DenseNetFCN', 'FCN8']

    ### load options
resume_experiment: False           # Restore the best model obtained in the experiment defined if exist
pretrained_model: 'basic'            # 'None': from scratch, 'basic': pretraned from imagenet, 'custom': personal model
input_model_path: None            # Path and pretrained file to load [None uses experiment path and model name by default]
load_weight_only: True            # Recomended true, loads only weights and parameters
basic_models_path: './pretrained_models/' # Path for the basic models (ImageNet weights) where they will be download
    ### Save options
save_weight_only: True            # Recomended true, stores only weights and parameters
model_name: 'VGG16'          # Name of the model to store
output_model_path: None            # Path to store the model using model_name [None uses the default experiment path]

# Loss type
loss_type: 'cross_entropy_segmentation' # options: ['cross_entropy_segmentation','focal_segmentation']
normalize_loss              : True

# General parameters

train_samples: -1 #-1 uses all the data available inside the dataset files
valid_samples: -1 #-1 uses all the data available inside the dataset files
test_samples: -1 #-1 uses all the data available inside the dataset files
train_batch_size: 8
valid_batch_size: 1
test_batch_size: 1
train: True
validation: True
test: True # Calculate metrics on test giving the gt
predict_test: True  # True when you want to generate predictions from test, doesn't need gt
predict_path_output: None # None uses the default output in the experiment folder /predictions

# Image properties
size_image_train: null #(1280, 960)

resize_image_train: !!python/tuple [224,224] #(320, 640)#(640, 480)
resize_image_valid: !!python/tuple [224,224] #(320, 640)#(640, 480)
resize_image_test: !!python/tuple [224,224] #(320, 640)#(640, 480)
crop_train: null
grayscale: False #Use this option to convert to rgb a grascale dataset

# Dataset properties


train_images_txt: '/home/grupo07/mcv/datasets/M5/classification/TT100K_trafficSigns/TT100K_trafficSigns_train_images.txt'
train_gt_txt: '/home/grupo07/mcv/datasets/M5/classification/TT100K_trafficSigns/TT100K_trafficSigns_train_gt.txt'
valid_images_txt: '/home/grupo07/mcv/datasets/M5/classification/TT100K_trafficSigns/TT100K_trafficSigns_valid_images.txt'
valid_gt_txt: '/home/grupo07/mcv/datasets/M5/classification/TT100K_trafficSigns/TT100K_trafficSigns_valid_gt.txt'
test_images_txt: '/home/grupo07/mcv/datasets/M5/classification/TT100K_trafficSigns/TT100K_trafficSigns_valid_images.txt'
test_gt_txt: '/home/grupo07/mcv/datasets/M5/classification/TT100K_trafficSigns/TT100K_trafficSigns_valid_gt.txt'

labels  : !!python/tuple ['i2','i4','i5','il100','il60','il80','io','ip','p10','p11','p12','p19','p23','p26','p27','p3','p5','p6','pg','ph4.5','ph4','ph5','pl100','pl120','pl20','pl30','pl40','pl50','pl5','pl60','pl70','pl80','pm20','pm30','pm55','pne','pn','po','pr40','w13','w32','w55','w57','w59','wo','i1']
map_labels  : !!python/dict {'i2': 0,'i4': 1,'i5': 2,'il100': 3,'il60': 4,'il80': 5,'io': 6,'ip': 7,'p10': 8,'p11': 9,'p12': 10,'p19': 11,'p23': 12,'p26': 13,'p27': 14,'p3': 15,'p5': 16,'p6': 17,'pg': 18,'ph4.5': 19,'ph4': 20,'ph5': 21,'pl100': 22,'pl120': 23,'pl20': 24,'pl30': 25,'pl40': 26,'pl50': 27,'pl5': 28,'pl60': 29,'pl70': 30,'pl80': 31,'pm20': 32,'pm30': 33,'pm55': 34,'pne': 35,'pn': 36,'po': 37,'pr40': 38,'w13': 39,'w32': 40,'w55': 41,'w57': 42,'w59': 43,'wo': 44, 'i1':45}
num_classes : 46
shuffle: True
void_class: 255   # void id or value on the image

# Training
epochs: 25     # Max number of epochs, use 0 to save directly a model, useful to make conversions
initial_epoch: 1     # Defines the starting epoch number
valid_samples_epoch: -1    # Number of validation images used to validate an epoch

    ### Optimizer ###
optimizer: 'SGD' #Options available ['SGD','Adam','RMSProp']
momentum1: 0.95
momentum2: 0.99
learning_rate: 1.0e-4
learning_rate_bias: 1.0e-4
weight_decay: 0.0005
    ### Scheduler
scheduler: 'ReduceLROnPlateau' # ['ReduceLROnPlateau','Step','MultiStep','Exponential', None]
decay: 0.1   # Learnng rate decay to apply (lr*decay)
sched_patience: 5     # ReduceLROnPlateau option: epoch patience without loss change until a lr decrement
step_size: 20    # Step option: epoch counter to decrease lr
milestone: [60,30,10] # MultiStep option: define different milestones (epochs) to decrease lr
    ### Save criteria
save_condition: 'valid_mIoU'        # ['always','(x)_loss','(x)_mAcc','(x)_mIoU'] x = valid or train_loss
    ### Early Stopping
early_stopping: True
stop_condition: 'valid_mIoU'        # [(x)_loss','(x)_mAcc','(x)_mIoU'] x = valid or train_loss
patience: 5

# Image preprocess
rescale: 1.
mean: [0.28689553, 0.32513301, 0.28389176] #[0.37296272, 0.37296272, 0.37296272]
std: [0.18696375, 0.19017339, 0.18720214] #[0.21090189, 0.21090189, 0.21090189]

# Data augmentation
hflips: False
random_dist                 : False  # Activate random distortions to the input image [brightness, contrast, saturation]

color_map: null
num_images: null